{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1aae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing necessary libraries for SVD microarray analysis \"\"\"\n",
    "\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy import sp\n",
    "from scipy.linalg import svd\n",
    "from scipy.sparse import eye as sparse_eye\n",
    "from scipy.linalg import solve\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be412bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loading the microarray data \"\"\"\n",
    "\n",
    "\n",
    "def carregar_matriz_microarray(caminho_arquivo: str, nome_variavel: str = \"MatrizNCBI\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Carrega a matriz de microarray a partir de um arquivo .mat exportado do MATLAB.\n",
    "\n",
    "    Args:\n",
    "        caminho_arquivo (str): Caminho para o arquivo .mat.\n",
    "        nome_variavel (str): Nome da variável dentro do .mat que contém a matriz de interesse.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Matriz de microarray como array NumPy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dados = scipy.loadmat(caminho_arquivo)\n",
    "        if nome_variavel not in dados:\n",
    "            raise KeyError(\n",
    "                f\"Variável '{nome_variavel}' não encontrada no arquivo.\")\n",
    "\n",
    "        matriz = dados[nome_variavel]\n",
    "\n",
    "        if not isinstance(matriz, np.ndarray):\n",
    "            raise TypeError(\n",
    "                f\"A variável '{nome_variavel}' não é uma matriz NumPy.\")\n",
    "\n",
    "        return matriz\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar a matriz: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd63608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Primeira Etapa - Decomposição ===\n",
    "# Escolher um microarray dentre os disponíveis no NCBI. Fazer o download da matriz, caracterizando o problema subjacente ao microarray como um vector space model,\n",
    "# onde se deseja resolver problemas de classificação. Descrever as entidades e o tipo de atributos utilizados. Resolver eventuais omissões como os atributos cujos valores não foram informados.\n",
    "\n",
    "# MatrizNCBI deve estar carregada como um np.ndarray (genes x amostras)\n",
    "# Seleção das colunas da matriz: aqui estou selecionando apenas os pacientes\n",
    "# controle (sem asma, do 1 ao 19) e os pacientes com asma severa (39 ao final), excluo os pacientes com asma moderada\n",
    "Ans = np.concatenate((MatrizNCBI[:, :19], MatrizNCBI[:, 38:]), axis=1)\n",
    "\n",
    "# SVD (decomposição em valores singulares) - usar os componentes para visualizar variância e calcular centróides,\n",
    "# é uma etapa de exploração dimensional.\n",
    "\n",
    "Ans = Ans.T\n",
    "\n",
    "Ans = Ans - np.mean(Ans, axis=0)  # Subtrai a média de cada coluna (gene)\n",
    "\n",
    "T, S_diag, Vt = svd(Ans, full_matrices=False)\n",
    "S = np.diag(S_diag)\n",
    "\n",
    "diagonal_S = S_diag\n",
    "dist_import_relativa = diagonal_S / np.sum(diagonal_S)\n",
    "\n",
    "plt.figure()\n",
    "plt.grid(True)\n",
    "plt.plot(dist_import_relativa, '*')\n",
    "plt.plot(dist_import_relativa)\n",
    "plt.show()\n",
    "\n",
    "# A matriz PC_scores representa as entidades (amostras) projetadas no novo espaço dos PCs (35x35).\n",
    "PC_scores = T @ S  # PC_scores será 35x35\n",
    "\n",
    "# Esses \"scores\" são as representações das suas 35 amostras em um novo espaço de menor dimensão,\n",
    "# onde os dados estão reorganizados para capturar a maior variação possível nos primeiros componentes (tipo PCA).\n",
    "\n",
    "# Labels: 0 para controle, 1 para asma severa\n",
    "labels = np.concatenate((np.zeros(19), np.ones(17)))\n",
    "\n",
    "# Índices\n",
    "controle_idx = (labels == 0)\n",
    "asma_idx = (labels == 1)\n",
    "\n",
    "# Cálculo dos centróides nos 3 primeiros PCs\n",
    "centroide_controle = PC_scores[controle_idx, :3].mean(axis=0)\n",
    "centroide_asma = PC_scores[asma_idx, :3].mean(axis=0)\n",
    "\n",
    "# Distância entre centróides\n",
    "distancia_centroide = np.linalg.norm(centroide_controle - centroide_asma)\n",
    "print(f'Distância entre centróides: {distancia_centroide:.4f}')\n",
    "\n",
    "# ANOVA\n",
    "\n",
    "group = np.array(['controle'] * 19 + ['asma'] * 17)\n",
    "anova_result = stats.f_oneway(\n",
    "    PC_scores[controle_idx, 0], PC_scores[asma_idx, 0])\n",
    "print(f'p-valor da ANOVA no PC1: {anova_result.pvalue:.4e}')\n",
    "\n",
    "# === Etapa 2 ===\n",
    "# Construção de um Classificador: usar um modelo de regressão logística modificada para proceder à classificação dos problemas associados, considerando a matriz de entidades completa.\n",
    "\n",
    "Aux = S @ Vt\n",
    "x = Aux[0, :]\n",
    "y = Aux[1, :]\n",
    "z = Aux[2, :]\n",
    "\n",
    "matriz_3x36 = np.array([x, y, z])\n",
    "\n",
    "# Criação do gráfico\n",
    "plt.figure()\n",
    "plt.title('Projeção das Amostras no Espaço PC1 x PC2')\n",
    "plt.xlabel('Primeiro Componente Principal (PC1)')\n",
    "plt.ylabel('Segundo Componente Principal (PC2)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.scatter(x[labels == 0], y[labels == 0], c='r', label='Controle')\n",
    "plt.scatter(x[labels == 1], y[labels == 1], facecolors='none',\n",
    "            edgecolors='r', label='Asma severa')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualização antes da regressão logística modificada\n",
    "\n",
    "Ans_Teste = np.concatenate((MatrizNCBI[:, :19], MatrizNCBI[:, 38:]), axis=1).T\n",
    "# Centraliza com média do Ans original\n",
    "Ans_Teste = Ans_Teste - np.mean(Ans, axis=0)\n",
    "\n",
    "U, S2_diag, Vt = svd(Ans_Teste, full_matrices=False)\n",
    "S2 = np.diag(S2_diag)\n",
    "PC_scores_Teste = U @ S2  # Projeção\n",
    "\n",
    "xt = PC_scores_Teste[:, 0]\n",
    "yt = PC_scores_Teste[:, 1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Projeção das Amostras no Espaço PC1 x PC2 (via SVD)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid(True)\n",
    "plt.scatter(xt[labels == 0], yt[labels == 0], c='r', label='Controle')\n",
    "plt.scatter(xt[labels == 1], yt[labels == 1], facecolors='none',\n",
    "            edgecolors='k', linewidths=1.2, label='Asma severa')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ======\n",
    "# Selection of the 10 most important markers\n",
    "\n",
    "\n",
    "def solve_system(A, b):\n",
    "    m, n = A.shape\n",
    "    Im = sparse_eye(m).toarray()\n",
    "    In = sparse_eye(n).toarray()\n",
    "    M = np.block([[Im, -A], [-A.T, In]])\n",
    "    nb = np.zeros(m + n)\n",
    "    nb[:m] = -b\n",
    "    x = np.linalg.solve(M, nb)\n",
    "    alpha = x[m:]\n",
    "    return alpha, x\n",
    "\n",
    "\n",
    "# Modified logistic regression thresholds\n",
    "logit_ch1 = 12\n",
    "logit_ch0 = -12\n",
    "\n",
    "DataMatrix = Ans.T  # genes x amostras (35 amostras)\n",
    "\n",
    "m, n = DataMatrix.shape\n",
    "b = np.zeros(n)\n",
    "b[:19] = logit_ch1\n",
    "b[19:] = logit_ch0\n",
    "\n",
    "alpha, _ = solve_system(DataMatrix.T, b)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Weights Associated with Attributes')\n",
    "plt.plot(alpha, '*')\n",
    "plt.show()\n",
    "\n",
    "aux = DataMatrix.T @ alpha\n",
    "num = np.exp(aux)\n",
    "p = num / (1 + num)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Logistic Regression Classification - All Attributes')\n",
    "plt.plot(p, '*')\n",
    "plt.show()\n",
    "\n",
    "# Validate the markers\n",
    "positions = np.argsort(alpha)\n",
    "selected = np.concatenate((positions[:7], positions[-7:]))\n",
    "\n",
    "ReducedMatrix = DataMatrix[selected, :]\n",
    "\n",
    "T, S_diag, Vt = svd(ReducedMatrix, full_matrices=False)\n",
    "singular_values = S_diag\n",
    "relative_importance = singular_values / np.sum(singular_values)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Relative Singular Values of the Reduced Matrix')\n",
    "plt.grid(True)\n",
    "plt.plot(relative_importance, '*')\n",
    "plt.plot(relative_importance)\n",
    "plt.show()\n",
    "\n",
    "AuxiliaryMatrix = np.diag(singular_values) @ Vt\n",
    "x = AuxiliaryMatrix[0, :]\n",
    "y = AuxiliaryMatrix[1, :]\n",
    "z = AuxiliaryMatrix[2, :]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Entity Domain Visualization')\n",
    "plt.grid(True)\n",
    "plt.plot(x, y, 'or')\n",
    "plt.plot(x[:20], y[:20], '*r')\n",
    "plt.show()\n",
    "\n",
    "# P(x) for the reduced matrix\n",
    "\n",
    "new_alpha = np.linalg.lstsq(ReducedMatrix.T, b, rcond=None)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Weights Associated with Selected Attributes')\n",
    "plt.plot(new_alpha, '*')\n",
    "plt.show()\n",
    "\n",
    "aux = ReducedMatrix.T @ new_alpha\n",
    "num = np.exp(aux)\n",
    "p = num / (1 + num)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Logistic Regression Classification - Selected Attributes')\n",
    "plt.plot(p, '*')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
