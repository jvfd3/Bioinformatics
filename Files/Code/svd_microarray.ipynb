{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1aae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing necessary libraries for SVD microarray analysis \"\"\"\n",
    "\n",
    "# %pip install numpy==2.3.0 pandas==2.3.0 matplotlib==3.10.3 scipy==1.15.3 ncbi-datasets-pylib==16.6.1 GEOparse==2.0.4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.linalg import svd\n",
    "from scipy.sparse import eye as sparse_eye\n",
    "from scipy.linalg import solve\n",
    "\n",
    "from ncbi.datasets import GeneApi # Not used\n",
    "import GEOparse as gp # Not used but could be useful for full streamlining the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2be412bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loading the microarray data \"\"\"\n",
    "\n",
    "def load_from_geneapi():\n",
    "    \"\"\" Function to load data from NCBI Gene API \"\"\"\n",
    "\n",
    "    gene_api = GeneApi()\n",
    "    print(type(gene_api))\n",
    "\n",
    "def load_from_geoparse():\n",
    "    \"\"\" Function to load data from GEOparse \"\"\"\n",
    "\n",
    "    # Example of loading a GEO dataset\n",
    "    gse = gp.get_GEO(\"GSE27011\")  # Replace with actual GEO accession number\n",
    "    print(type(gse))\n",
    "\n",
    "def load_from_manual_selected_series():\n",
    "    \"\"\" Function to load manually selected series data \"\"\"\n",
    "    # Read data from a CSV file\n",
    "    path = \"../Data/manual_series_splitting.csv\"\n",
    "    df = pd.read_csv(path, delimiter=',', header=0)  # Replace with actual file path\n",
    "    # print(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "MatrizNCBI = load_from_manual_selected_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd63608",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Primeira Etapa - Decomposição \"\"\"\n",
    "\n",
    "# Escolher um microarray dentre os disponíveis no NCBI. Fazer o download da matriz, caracterizando o problema subjacente ao microarray como um vector space model,\n",
    "# onde se deseja resolver problemas de classificação. Descrever as entidades e o tipo de atributos utilizados. Resolver eventuais omissões como os atributos cujos valores não foram informados.\n",
    "\n",
    "# MatrizNCBI deve estar carregada como um np.ndarray (genes x amostras)\n",
    "# Seleção das colunas da matriz: aqui estou selecionando apenas os pacientes\n",
    "# controle (sem asma, do 1 ao 19) e os pacientes com asma severa (39 ao final), excluo os pacientes com asma moderada\n",
    "Ans = np.concatenate((MatrizNCBI[:, :19], MatrizNCBI[:, 38:]), axis=1)\n",
    "\n",
    "# SVD (decomposição em valores singulares) - usar os componentes para visualizar variância e calcular centróides,\n",
    "# é uma etapa de exploração dimensional.\n",
    "\n",
    "Ans = Ans.T\n",
    "\n",
    "Ans = Ans - np.mean(Ans, axis=0)  # Subtrai a média de cada coluna (gene)\n",
    "\n",
    "T, S_diag, Vt = svd(Ans, full_matrices=False)\n",
    "S = np.diag(S_diag)\n",
    "\n",
    "diagonal_S = S_diag\n",
    "dist_import_relativa = diagonal_S / np.sum(diagonal_S)\n",
    "\n",
    "plt.figure()\n",
    "plt.grid(True)\n",
    "plt.plot(dist_import_relativa, '*')\n",
    "plt.plot(dist_import_relativa)\n",
    "plt.show()\n",
    "\n",
    "# A matriz PC_scores representa as entidades (amostras) projetadas no novo espaço dos PCs (35x35).\n",
    "PC_scores = T @ S  # PC_scores será 35x35\n",
    "\n",
    "# Esses \"scores\" são as representações das suas 35 amostras em um novo espaço de menor dimensão,\n",
    "# onde os dados estão reorganizados para capturar a maior variação possível nos primeiros componentes (tipo PCA).\n",
    "\n",
    "# Labels: 0 para controle, 1 para asma severa\n",
    "labels = np.concatenate((np.zeros(19), np.ones(17)))\n",
    "\n",
    "# Índices\n",
    "controle_idx = (labels == 0)\n",
    "asma_idx = (labels == 1)\n",
    "\n",
    "# Cálculo dos centróides nos 3 primeiros PCs\n",
    "centroide_controle = PC_scores[controle_idx, :3].mean(axis=0)\n",
    "centroide_asma = PC_scores[asma_idx, :3].mean(axis=0)\n",
    "\n",
    "# Distância entre centróides\n",
    "distancia_centroide = np.linalg.norm(centroide_controle - centroide_asma)\n",
    "print(f'Distância entre centróides: {distancia_centroide:.4f}')\n",
    "\n",
    "# ANOVA\n",
    "\n",
    "group = np.array(['controle'] * 19 + ['asma'] * 17)\n",
    "anova_result = stats.f_oneway(\n",
    "    PC_scores[controle_idx, 0], PC_scores[asma_idx, 0])\n",
    "print(f'p-valor da ANOVA no PC1: {anova_result.pvalue:.4e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5dc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Etapa 2 \"\"\"\n",
    "# Construção de um Classificador: usar um modelo de regressão logística modificada para proceder à classificação dos problemas associados, considerando a matriz de entidades completa.\n",
    "\n",
    "Aux = S @ Vt\n",
    "x = Aux[0, :]\n",
    "y = Aux[1, :]\n",
    "z = Aux[2, :]\n",
    "\n",
    "matriz_3x36 = np.array([x, y, z])\n",
    "\n",
    "# Criação do gráfico\n",
    "plt.figure()\n",
    "plt.title('Projeção das Amostras no Espaço PC1 x PC2')\n",
    "plt.xlabel('Primeiro Componente Principal (PC1)')\n",
    "plt.ylabel('Segundo Componente Principal (PC2)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.scatter(x[labels == 0], y[labels == 0], c='r', label='Controle')\n",
    "plt.scatter(x[labels == 1], y[labels == 1], facecolors='none',\n",
    "            edgecolors='r', label='Asma severa')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualização antes da regressão logística modificada\n",
    "\n",
    "Ans_Teste = np.concatenate((MatrizNCBI[:, :19], MatrizNCBI[:, 38:]), axis=1).T\n",
    "# Centraliza com média do Ans original\n",
    "Ans_Teste = Ans_Teste - np.mean(Ans, axis=0)\n",
    "\n",
    "U, S2_diag, Vt = svd(Ans_Teste, full_matrices=False)\n",
    "S2 = np.diag(S2_diag)\n",
    "PC_scores_Teste = U @ S2  # Projeção\n",
    "\n",
    "xt = PC_scores_Teste[:, 0]\n",
    "yt = PC_scores_Teste[:, 1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Projeção das Amostras no Espaço PC1 x PC2 (via SVD)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid(True)\n",
    "plt.scatter(xt[labels == 0], yt[labels == 0], c='r', label='Controle')\n",
    "plt.scatter(xt[labels == 1], yt[labels == 1], facecolors='none',\n",
    "            edgecolors='k', linewidths=1.2, label='Asma severa')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ======\n",
    "# Selection of the 10 most important markers\n",
    "\n",
    "\n",
    "def solve_system(A, b):\n",
    "    m, n = A.shape\n",
    "    Im = sparse_eye(m).toarray()\n",
    "    In = sparse_eye(n).toarray()\n",
    "    M = np.block([[Im, -A], [-A.T, In]])\n",
    "    nb = np.zeros(m + n)\n",
    "    nb[:m] = -b\n",
    "    x = np.linalg.solve(M, nb)\n",
    "    alpha = x[m:]\n",
    "    return alpha, x\n",
    "\n",
    "\n",
    "# Modified logistic regression thresholds\n",
    "logit_ch1 = 12\n",
    "logit_ch0 = -12\n",
    "\n",
    "DataMatrix = Ans.T  # genes x amostras (35 amostras)\n",
    "\n",
    "m, n = DataMatrix.shape\n",
    "b = np.zeros(n)\n",
    "b[:19] = logit_ch1\n",
    "b[19:] = logit_ch0\n",
    "\n",
    "alpha, _ = solve_system(DataMatrix.T, b)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Weights Associated with Attributes')\n",
    "plt.plot(alpha, '*')\n",
    "plt.show()\n",
    "\n",
    "aux = DataMatrix.T @ alpha\n",
    "num = np.exp(aux)\n",
    "p = num / (1 + num)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Logistic Regression Classification - All Attributes')\n",
    "plt.plot(p, '*')\n",
    "plt.show()\n",
    "\n",
    "# Validate the markers\n",
    "positions = np.argsort(alpha)\n",
    "selected = np.concatenate((positions[:7], positions[-7:]))\n",
    "\n",
    "ReducedMatrix = DataMatrix[selected, :]\n",
    "\n",
    "T, S_diag, Vt = svd(ReducedMatrix, full_matrices=False)\n",
    "singular_values = S_diag\n",
    "relative_importance = singular_values / np.sum(singular_values)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Relative Singular Values of the Reduced Matrix')\n",
    "plt.grid(True)\n",
    "plt.plot(relative_importance, '*')\n",
    "plt.plot(relative_importance)\n",
    "plt.show()\n",
    "\n",
    "AuxiliaryMatrix = np.diag(singular_values) @ Vt\n",
    "x = AuxiliaryMatrix[0, :]\n",
    "y = AuxiliaryMatrix[1, :]\n",
    "z = AuxiliaryMatrix[2, :]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Entity Domain Visualization')\n",
    "plt.grid(True)\n",
    "plt.plot(x, y, 'or')\n",
    "plt.plot(x[:20], y[:20], '*r')\n",
    "plt.show()\n",
    "\n",
    "# P(x) for the reduced matrix\n",
    "\n",
    "new_alpha = np.linalg.lstsq(ReducedMatrix.T, b, rcond=None)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Weights Associated with Selected Attributes')\n",
    "plt.plot(new_alpha, '*')\n",
    "plt.show()\n",
    "\n",
    "aux = ReducedMatrix.T @ new_alpha\n",
    "num = np.exp(aux)\n",
    "p = num / (1 + num)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Logistic Regression Classification - Selected Attributes')\n",
    "plt.plot(p, '*')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
